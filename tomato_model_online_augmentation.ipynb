{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df717120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(img, transform):\n",
    "    plt.imshow(img.permute(1, 2, 0)  )\n",
    "#     image = transform(img)\n",
    "#     plt.imshow(image.permute(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbf7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomGrayscale(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomInvert(),\n",
    "    transforms.RandomRotation(30),\n",
    "])\n",
    "\n",
    "# Uncomment the below line based on where you train the model----------------------------------------\n",
    "# !mkdir /kaggle/working/Tomato\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# !cp -r /kaggle/input/plant-diseases/dataset_itr2/dataset_itr2/test/Tomato* /kaggle/working/Tomato\n",
    "# !cp -r /kaggle/input/plant-diseases/dataset_itr2/dataset_itr2/train/Tomato* /kaggle/working/Tomato\n",
    "\n",
    "# !rm -rf /kaggle/working/Tomato/Tomato___Leaf_Mold\n",
    "# !rm -rf /kaggle/working/Tomato/Tomato___Tomato_mosaic_virus \n",
    "\n",
    "# Uncomment this for training on kaggle\n",
    "# data = datasets.ImageFolder('/kaggle/working/Tomato', transform=transform)----------------------------\n",
    "\n",
    "\n",
    "# This is for training on Local Machine\n",
    "# data = datasets.ImageFolder('dataset', transform=transform)\n",
    "\n",
    "\n",
    "# Split into train/test sets:\n",
    "train_len = int(len(data)*0.65)\n",
    "train_set, test_set = random_split(data, [train_len, len(data) - train_len])\n",
    "\n",
    "# Extract classes:\n",
    "train_classes = [train_set.dataset.targets[i] for i in train_set.indices]\n",
    "# Calculate support:\n",
    "class_count = Counter(train_classes)\n",
    "# Calculate class weights:\n",
    "class_weights = torch.DoubleTensor([len(train_classes)/c for c in pd.Series(class_count).sort_index().values]) \n",
    "# Sampler needs the respective class weight supplied for each image in the dataset:\n",
    "sample_weights = [class_weights[train_set.dataset.targets[i]] for i in train_set.indices]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=int(len(train_set)*2), replacement=True)\n",
    "\n",
    "batch_size=4\n",
    "\n",
    "# Create torch dataloaders:\n",
    "\n",
    "dataloaders = DataLoader(data, batch_size=4, sampler=sampler, num_workers=6)\n",
    "print(\"The total number of images is:\", len(dataloaders))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, sampler=sampler, num_workers=6)\n",
    "print(\"The number of images in a training set is:\", len(train_loader)*batch_size)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=6)\n",
    "print(\"The number of images in a test set is:\", len(test_loader)*batch_size)\n",
    "print(dataloaders.dataset)\n",
    "\n",
    "# x, y = next(iter(dataloaders[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"CPU\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_iters = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b68f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.cnn = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc = nn.Linear(32*64*64, 512)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(512, 8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = NeuralNetwork()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c97e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71571fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model,loss_fn,dataloader,optimizer,epoch):\n",
    "  print('\\nEpoch : %d'%epoch)\n",
    "  total_loss=0    \n",
    "  correct=0\n",
    "  total=0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for data in tqdm(dataloader):\n",
    "    \n",
    "    inputs,labels=data[0].to(device),data[1].to(device)\n",
    "    \n",
    "    outputs=model(inputs)\n",
    "    \n",
    "    loss=loss_fn(outputs,labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    _, predicted = outputs.max(1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels).sum().item()\n",
    "      \n",
    "  loss=total_loss/len(dataloader)\n",
    "  accuracy=100.*correct/total\n",
    "  \n",
    "  accuracies['train'].append(accuracy)\n",
    "  losses['train'].append(loss)\n",
    "  print('Train Loss: %.3f | Accuracy: %.3f'%(loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,loss_fn,dataloader,epoch):\n",
    "#   model.eval()\n",
    "\n",
    "  total_loss=0\n",
    "  correct=0\n",
    "  total=0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data in tqdm(dataloader):\n",
    "      images,labels=data[0].to(device),data[1].to(device)\n",
    "      \n",
    "      outputs=model(images)\n",
    "\n",
    "      loss= loss_fn(outputs,labels)\n",
    "      total_loss+=loss.item()\n",
    "      \n",
    "      _, predicted = outputs.max(1)\n",
    "      total += labels.size(0)\n",
    "      correct += predicted.eq(labels).sum().item()\n",
    "  \n",
    "  loss=total_loss/len(dataloader)\n",
    "  accuracy=100.*correct/total\n",
    "\n",
    "  losses['val'].append(loss)\n",
    "  accuracies['val'].append(accuracy)\n",
    "\n",
    "  print('Test Loss: %.3f | Accuracy: %.3f'%(loss,accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b24701",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'train':[], 'val':[]}\n",
    "accuracies = {'train':[], 'val':[]}\n",
    "epochs=30\n",
    "for epoch in range(1,epochs+1): \n",
    "  train(model,loss_fn,train_loader,optimizer_ft,epoch)\n",
    "  test(model,loss_fn,val_loader,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing classification accuracy for individual classes.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0bcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(accuracies['train'], label='Training Accuracy')\n",
    "plt.plot(accuracies['val'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(losses['train'], label='Training Loss')\n",
    "plt.plot(losses['val'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e302ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the paths accordingly!!\n",
    "\n",
    "torch.save(model.state_dict(), '/kaggle/working/tomato.pk1')\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save('/kaggle/working/tomato_scripted.pt') # Save\n",
    "\n",
    "import os \n",
    "os.chdir(r'/kaggle/working')\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'tomato_scripted.pt')\n",
    "\n",
    "import os \n",
    "os.chdir(r'/kaggle/working')\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'tomato.pk1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
