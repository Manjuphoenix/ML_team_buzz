{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport torch\nimport torchvision\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)\n\n\n!mkdir /kaggle/working/Tomato\n!mkdir /kaggle/working/Tomato/test\n!mkdir /kaggle/working/Tomato/train\n\n!cp -r /kaggle/input/plant-diseases/dataset_itr2/dataset_itr2/test/Tomato* /kaggle/working/Tomato/test\n!cp -r /kaggle/input/plant-diseases/dataset_itr2/dataset_itr2/train/Tomato* /kaggle/working/Tomato/train","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-03T03:44:34.039853Z","iopub.execute_input":"2022-06-03T03:44:34.040588Z","iopub.status.idle":"2022-06-03T03:49:42.892951Z","shell.execute_reply.started":"2022-06-03T03:44:34.040480Z","shell.execute_reply":"2022-06-03T03:49:42.891785Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"PyTorch Version:  1.11.0\nTorchvision Version:  0.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path='/kaggle/working/Tomato/train'\ntest_path='/kaggle/working/Tomato/test'\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:49:42.896481Z","iopub.execute_input":"2022-06-03T03:49:42.897070Z","iopub.status.idle":"2022-06-03T03:49:42.952556Z","shell.execute_reply.started":"2022-06-03T03:49:42.897006Z","shell.execute_reply":"2022-06-03T03:49:42.951408Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"transfrom = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:49:42.954280Z","iopub.execute_input":"2022-06-03T03:49:42.954752Z","iopub.status.idle":"2022-06-03T03:49:42.964510Z","shell.execute_reply.started":"2022-06-03T03:49:42.954707Z","shell.execute_reply":"2022-06-03T03:49:42.963429Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\n\ntest_dataset=ImageFolder(test_path,transform=transfrom)\ntrain_dataset=ImageFolder(train_path,transform=transfrom)\n\nbatch = 32\nn_iter = 3000\nepochs = n_iter / (len(train_dataset) / batch)\nepochs = int(epochs)\n\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch, shuffle=True, num_workers=2)\n\ntestloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:49:42.967116Z","iopub.execute_input":"2022-06-03T03:49:42.967819Z","iopub.status.idle":"2022-06-03T03:49:43.387926Z","shell.execute_reply.started":"2022-06-03T03:49:42.967771Z","shell.execute_reply":"2022-06-03T03:49:43.387110Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n\n\nAlexNet_model.eval()\nmodel = AlexNet_model.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:57:38.493040Z","iopub.execute_input":"2022-06-03T03:57:38.493351Z","iopub.status.idle":"2022-06-03T03:57:39.319457Z","shell.execute_reply.started":"2022-06-03T03:57:38.493315Z","shell.execute_reply":"2022-06-03T03:57:39.318613Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.autograd import Variable\nnum_epochs = 10\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 0.01\noptimizer = optim.Adam(AlexNet_model.parameters(), lr=0.001)\n\niter = 0\nfor epoch in range(int(num_epochs)):\n    for i, (images, labels) in enumerate(trainloader):\n        images = Variable(images.cuda())\n        labels = Variable(labels.cuda())\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        iter += 1\n        \n        if iter % 500 == 0:\n            correct = 0\n            total = 0\n            for images, labels in testloader:\n                images = Variable(images.cuda())\n                outputs = model(images)\n                \n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                \n                if torch.cuda.is_available():\n                    correct += (predicted.cpu() == labels.cpu()).sum()\n                else:\n                    correct += (predicted == labels).sum()\n                \n            accuracy = 100 * correct / total\n            print('Iteration: {}. Loss {}. Accuracy: {}'.format(iter, loss.data, accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:57:39.320993Z","iopub.execute_input":"2022-06-03T03:57:39.321313Z","iopub.status.idle":"2022-06-03T05:06:50.963243Z","shell.execute_reply.started":"2022-06-03T03:57:39.321273Z","shell.execute_reply":"2022-06-03T05:06:50.962219Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Iteration: 500. Loss 1.3370039463043213. Accuracy: 56.353363037109375\nIteration: 1000. Loss 0.60061115026474. Accuracy: 75.50992584228516\nIteration: 1500. Loss 0.41946089267730713. Accuracy: 75.7786636352539\nIteration: 2000. Loss 0.6420803666114807. Accuracy: 81.73925018310547\nIteration: 2500. Loss 0.42754411697387695. Accuracy: 83.42061614990234\nIteration: 3000. Loss 0.8242958784103394. Accuracy: 78.8726577758789\nIteration: 3500. Loss 0.5978414416313171. Accuracy: 83.38616180419922\nIteration: 4000. Loss 0.4555121064186096. Accuracy: 87.72050476074219\nIteration: 4500. Loss 0.27992281317710876. Accuracy: 86.04602813720703\nIteration: 5000. Loss 0.24130098521709442. Accuracy: 88.7403564453125\nIteration: 5500. Loss 0.17565330862998962. Accuracy: 88.74724578857422\nIteration: 6000. Loss 0.6015636920928955. Accuracy: 88.25110626220703\nIteration: 6500. Loss 0.34836477041244507. Accuracy: 88.42337036132812\nIteration: 7000. Loss 0.6701751947402954. Accuracy: 83.48263549804688\nIteration: 7500. Loss 0.07166414707899094. Accuracy: 89.06422424316406\nIteration: 8000. Loss 0.3479905128479004. Accuracy: 87.93412017822266\nIteration: 8500. Loss 0.24891297519207. Accuracy: 80.8641128540039\nIteration: 9000. Loss 0.3389431834220886. Accuracy: 91.99283599853516\nIteration: 9500. Loss 0.39496755599975586. Accuracy: 89.33985900878906\nIteration: 10000. Loss 0.22765694558620453. Accuracy: 90.44927978515625\nIteration: 10500. Loss 0.2666802704334259. Accuracy: 91.2555160522461\nIteration: 11000. Loss 0.24651338160037994. Accuracy: 90.1805419921875\nIteration: 11500. Loss 0.8776864409446716. Accuracy: 88.51295471191406\nIteration: 12000. Loss 0.2070578783750534. Accuracy: 90.71113586425781\nIteration: 12500. Loss 0.23170047998428345. Accuracy: 90.2907943725586\nIteration: 13000. Loss 0.5191647410392761. Accuracy: 88.69900512695312\nIteration: 13500. Loss 0.4400826096534729. Accuracy: 89.6017074584961\nIteration: 14000. Loss 0.6517529487609863. Accuracy: 91.02122497558594\nIteration: 14500. Loss 0.23869547247886658. Accuracy: 86.10804748535156\nIteration: 15000. Loss 0.2616942822933197. Accuracy: 92.28913879394531\nIteration: 15500. Loss 0.2688983976840973. Accuracy: 91.2348403930664\nIteration: 16000. Loss 0.26885366439819336. Accuracy: 92.08930206298828\nIteration: 16500. Loss 0.15620362758636475. Accuracy: 92.17888641357422\nIteration: 17000. Loss 0.28144973516464233. Accuracy: 89.11934661865234\nIteration: 17500. Loss 0.24381370842456818. Accuracy: 92.27536010742188\nIteration: 18000. Loss 0.22227908670902252. Accuracy: 89.69818115234375\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-27T03:28:53.627088Z","iopub.execute_input":"2022-05-27T03:28:53.62762Z","iopub.status.idle":"2022-05-27T03:28:58.207145Z","shell.execute_reply.started":"2022-05-27T03:28:53.627562Z","shell.execute_reply":"2022-05-27T03:28:58.206164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.autograd import Variable\nimport numpy as np\nimport pylab as pl\nimport torch.nn.init as init","metadata":{"execution":{"iopub.status.busy":"2022-05-27T03:28:58.210027Z","iopub.execute_input":"2022-05-27T03:28:58.210704Z","iopub.status.idle":"2022-05-27T03:28:58.220329Z","shell.execute_reply.started":"2022-05-27T03:28:58.210657Z","shell.execute_reply":"2022-05-27T03:28:58.219351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn as nn\n\n#Loss\ncriterion = nn.CrossEntropyLoss()\n\n#Optimizer(SGD)\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nfor epoch in range(epochs):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n        inputs = Variable(inputs.cuda())\n        labels = Variable(labels.cuda())\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        output = model(inputs)\n        loss = criterion(output, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training of AlexNet')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T03:28:58.222509Z","iopub.execute_input":"2022-05-27T03:28:58.222728Z","iopub.status.idle":"2022-05-27T03:28:58.980506Z","shell.execute_reply.started":"2022-05-27T03:28:58.2227Z","shell.execute_reply":"2022-05-27T03:28:58.979181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}