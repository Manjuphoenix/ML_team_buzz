{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport scipy\nfrom PIL import Image\nfrom scipy import ndimage\n\nimport torch\nimport torchvision\n\nfrom torch import utils\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, transforms\nimport torchvision.models as models\n\nimport copy\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        [0.485, 0.456,0.406],\n        [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(\n        [0.485, 0.456, 0.406],\n        [0.229, 0.224, 0.225])])\n\n\ntrain_set = torchvision.datasets.ImageFolder('/kaggle/working/train', transform=train_transforms)\ntest_set = torchvision.datasets.ImageFolder('/kaggle/working/test', transform=test_transforms)\n\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)\n\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nprint(train_loader)\nprint(test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Create the neural network layers\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1))\n        self.layer2 = nn.AdaptiveAvgPool2d(output_size=(4096))\n        self.layer3 = nn.Sequential(\n                nn.Linear(in_features=57344, out_features=4096, bias=True),\n                nn.ReLU(),\n                nn.Dropout(p=0.5),\n                nn.Linear(in_features=4096, out_features=4096, bias=True),\n                nn.ReLU(),\n                nn.Dropout(p=0.5),\n                nn.Linear(in_features=4096, out_features=10, bias=True),\n            )\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        return output\n\n\nmodel = NeuralNetwork()\n\ndef train_model(train_loader, model):\n    # define the optimization\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    # enumerate epochs\n    for epoch in range(100):\n        # enumerate mini batches\n        for i, (inputs, targets) in enumerate(train_loader):\n            # clear the gradients\n            optimizer.zero_grad()\n            # compute the model output\n            yhat = model(torch.tensor(inputs))\n            # calculate loss\n            loss = criterion(yhat, targets)\n            # credit assignment\n            loss.backward()\n            # update model weights\n            optimizer.step()\n \n# evaluate the model\ndef evaluate_model(test_dl, model):\n    predictions, actuals = list(), list()\n    for i, (inputs, targets) in enumerate(test_loader):\n        # evaluate the model on the test set\n        inputs.is_cuda\n        targets.is_cuda\n        print(input)\n        yhat = model(inputs)\n        # retrieve numpy array\n        yhat = yhat.detach().numpy()\n        actual = targets.numpy()\n        actual = actual.reshape((len(actual), 1))\n        # round to class values\n        yhat = yhat.round()\n        # store\n        predictions.append(yhat)\n        actuals.append(actual)\n    predictions, actuals = vstack(predictions), vstack(actuals)\n    # calculate accuracy\n    acc = accuracy_score(actuals, predictions)\n    return acc\n \n# make a class prediction for one row of data\ndef predict(row, model):\n    # convert row to data\n    row = Tensor([row])\n    # make prediction\n    yhat = model(row)\n    # retrieve numpy array\n    yhat = yhat.detach().numpy()\n    return yhat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_model(train_loader, model)\n# evaluate the model\nacc = evaluate_model(test_loader, model)\nprint('Accuracy: %.3f' % acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}