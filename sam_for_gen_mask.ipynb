{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1BbfV0hegcpFzJqho7Mqa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manjuphoenix/ML_team_buzz/blob/michelle/sam_for_gen_mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgS8jFPMnj5h",
        "outputId": "e86b1523-0382-4801-9a82-6f8aed3c0dd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Segment Anything Model (SAM) and other dependencies"
      ],
      "metadata": {
        "id": "YN3DPGZSn57p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H9YruJen0Q8",
        "outputId": "c1744852-b3aa-4ec0-8cc8-67a5fb955028"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-ed9zehz0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-ed9zehz0\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment-anything\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36589 sha256=a4b1d90d04a2e4a15955b059404d8b2301c5941a10e2e048f0bac31abe74c050\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s5_x0k4a/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment-anything\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3CtzYroC2Lb",
        "outputId": "d266305b-144e-41ad-e3bc-d9a2b77829bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download SAM weights"
      ],
      "metadata": {
        "id": "2VeYIWh1iDWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aszw1OxBwowI",
        "outputId": "5d0faa8b-52a7-42cb-b5ee-6a8c5adf1bb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxoFmhsHw_fG",
        "outputId": "0dd34ea8-85cd-41fc-d310-7f536a102e13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/sam_vit_h_4b8939.pth ; exist: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "vlhbd_f4xfiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\""
      ],
      "metadata": {
        "id": "t6_9PSZupghA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
      ],
      "metadata": {
        "id": "n41g6y-Zx-9x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visdrone class labels\n",
        "# names:\n",
        "#   0: pedestrian\n",
        "#   1: people\n",
        "#   2: bicycle\n",
        "#   3: car\n",
        "#   4: van\n",
        "#   5: truck\n",
        "#   6: tricycle\n",
        "#   7: awning-tricycle\n",
        "#   8: bus\n",
        "#   9: motor"
      ],
      "metadata": {
        "id": "6rYIJwLUFN8z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/0000006_00159_d_0000001.txt\") as f:\n",
        "  content = f.readlines()\n",
        "ped = 0\n",
        "peo = 0\n",
        "bic = 0\n",
        "car = 0\n",
        "van = 0\n",
        "tru = 0\n",
        "tri = 0\n",
        "awn = 0\n",
        "bus = 0\n",
        "mot = 0\n",
        "\n",
        "for i in range(len(content)):\n",
        "  content[i] = content[i].replace(\"\\n\", \"\")\n",
        "  if content[i][-1]==\"0\":\n",
        "    ped+=1\n",
        "    # content[i][-1]=\"pedestrian\"\n",
        "  elif content[i][-1]==\"1\":\n",
        "    peo+=1\n",
        "    # content[i][-1]=\"people\"\n",
        "  elif content[i][-1]==\"2\":\n",
        "    bic+=1\n",
        "    # content[i][-1]=\"bicycle\"\n",
        "  elif content[i][-1]==\"3\":\n",
        "    car+=1\n",
        "    # content[i][-1]=\"car\"\n",
        "  elif content[i][-1]==\"4\":\n",
        "    van+=1\n",
        "    # content[i][-1]=\"van\"\n",
        "  elif content[i][-1]==\"5\":\n",
        "    tru+=1\n",
        "    # content[i][-1]=\"truck\"\n",
        "  elif content[i][-1]==\"6\":\n",
        "    tri+=1\n",
        "    # content[i][-1]=\"tricycle\"\n",
        "  elif content[i][-1]==\"7\":\n",
        "    awn+=1\n",
        "    # content[i][-1]=\"awing tricycle\"\n",
        "  elif content[i][-1]==\"8\":\n",
        "    bus+=1\n",
        "    # content[i][-1]=\"bus\"\n",
        "  elif content[i][-1]==\"9\":\n",
        "    mot+=1\n",
        "    # content[i][-1]=\"motorcycle\"\n",
        "\n",
        "print(content)\n",
        "print(\"Number of objects: \", len(content))\n",
        "print(\"Number of Pedestrians: \", ped)\n",
        "print(\"Number of People: \", peo)\n",
        "print(\"Number of Bicycle: \", bic)\n",
        "print(\"Number of Car: \", car)\n",
        "print(\"Number of Van: \", van)\n",
        "print(\"Number of Truck: \", tru)\n",
        "print(\"Number of Tricycle: \", tri)\n",
        "print(\"Number of Awning Tricycle: \", awn)\n",
        "print(\"Number of Bus: \", bus)\n",
        "print(\"Number of Motorcycle: \", mot)\n",
        "new_list = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkmn16vI5H20",
        "outputId": "be7d97df-a9bb-4356-e8f4-fdf9556aa7e3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['685,463,110,65,1,4,0,0', '578,328,36,38,1,4,0,0', '617,327,38,44,1,4,0,0', '659,350,90,40,1,4,0,0', '761,346,40,44,1,4,0,0', '805,350,38,41,1,4,0,0', '849,346,45,47,1,4,0,0', '895,349,43,44,1,4,0,0', '886,297,40,43,1,4,0,0', '810,305,70,40,1,4,0,0', '805,256,46,28,1,4,0,0', '783,234,70,27,1,4,0,0', '435,535,134,57,1,4,0,0', '488,507,118,52,1,4,0,1', '495,473,120,46,1,4,0,1', '507,447,107,38,1,4,0,1', '473,422,104,46,1,4,0,1', '913,179,33,31,1,4,0,0', '995,126,39,23,1,4,0,0', '922,106,20,21,1,4,0,0', '862,154,10,17,1,4,0,0', '1217,146,40,21,1,4,0,0', '1134,159,9,22,1,1,0,0', '1060,138,15,19,1,1,0,0', '1038,159,11,17,1,1,0,0', '387,215,144,51,0,11,0,0', '331,149,94,65,1,6,0,0', '296,152,104,65,1,6,0,2', '179,136,107,64,1,6,0,0', '139,138,118,62,1,6,0,2', '79,135,98,52,1,6,0,0', '32,140,92,40,1,6,0,0', '3,138,44,46,1,6,0,1', '0,231,91,89,1,6,1,0', '0,380,55,65,1,4,1,0', '29,393,89,59,1,4,0,1', '99,398,64,38,1,4,0,1', '165,392,58,37,1,4,0,1', '220,400,51,39,1,4,0,1', '315,409,42,19,1,10,0,0', '685,121,31,20,1,5,0,0', '1306,153,54,43,1,6,0,0', '1273,152,84,39,1,6,0,1', '1036,106,20,14,1,4,0,0', '866,108,12,17,0,11,0,0', '867,99,6,10,1,1,0,0', '745,130,38,18,1,4,0,2', '853,67,14,12,1,4,0,0', '917,99,13,14,1,4,0,1', '840,50,12,10,1,4,0,0', '857,44,9,12,1,4,0,0', '846,36,12,11,1,4,0,0', '840,43,9,10,1,4,0,0', '820,41,11,10,1,4,0,0', '830,35,8,11,1,4,0,0', '826,26,10,8,1,4,0,0', '802,23,9,8,1,4,0,0', '769,46,24,8,1,4,0,0', '831,17,8,7,1,4,0,0', '680,0,80,49,0,0,0,0', '763,5,6,6,1,4,0,0', '771,4,7,7,1,4,0,0', '769,11,7,5,1,4,0,0', '790,10,7,7,1,4,0,0', '780,10,8,7,1,4,0,0', '781,4,5,6,1,4,0,0', '884,27,12,8,1,4,0,0', '878,26,10,7,1,4,0,1', '792,3,6,6,1,4,0,0', '805,7,6,9,1,4,0,0', '798,1,5,8,1,4,0,0', '820,0,55,31,0,0,0,0', '1193,137,47,17,1,4,0,1', '31,139,92,40,1,6,0,2', '288,414,23,14,1,10,0,2']\n",
            "Number of objects:  75\n",
            "Number of Pedestrians:  57\n",
            "Number of People:  13\n",
            "Number of Bicycle:  5\n",
            "Number of Car:  0\n",
            "Number of Van:  0\n",
            "Number of Truck:  0\n",
            "Number of Tricycle:  0\n",
            "Number of Awning Tricycle:  0\n",
            "Number of Bus:  0\n",
            "Number of Motorcycle:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab0 = \"pedestrain\"\n",
        "for i in range(len(content)):\n",
        "  if content[i][-1]==\"0\":\n",
        "    content[i] += (\",pedestrian\")\n",
        "    new_list.append(content[i].split(','))\n",
        "    # new_list += content[i]\n",
        "print(new_list)\n",
        "print(\"Number of pedestrain labels: \", len(new_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46-tfW3k5Hz-",
        "outputId": "beb00ae2-e664-4549-8082-61e74ebc86d9"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['685', '463', '110', '65', '1', '4', '0', '0', 'pedestrian'], ['578', '328', '36', '38', '1', '4', '0', '0', 'pedestrian'], ['617', '327', '38', '44', '1', '4', '0', '0', 'pedestrian'], ['659', '350', '90', '40', '1', '4', '0', '0', 'pedestrian'], ['761', '346', '40', '44', '1', '4', '0', '0', 'pedestrian'], ['805', '350', '38', '41', '1', '4', '0', '0', 'pedestrian'], ['849', '346', '45', '47', '1', '4', '0', '0', 'pedestrian'], ['895', '349', '43', '44', '1', '4', '0', '0', 'pedestrian'], ['886', '297', '40', '43', '1', '4', '0', '0', 'pedestrian'], ['810', '305', '70', '40', '1', '4', '0', '0', 'pedestrian'], ['805', '256', '46', '28', '1', '4', '0', '0', 'pedestrian'], ['783', '234', '70', '27', '1', '4', '0', '0', 'pedestrian'], ['435', '535', '134', '57', '1', '4', '0', '0', 'pedestrian'], ['913', '179', '33', '31', '1', '4', '0', '0', 'pedestrian'], ['995', '126', '39', '23', '1', '4', '0', '0', 'pedestrian'], ['922', '106', '20', '21', '1', '4', '0', '0', 'pedestrian'], ['862', '154', '10', '17', '1', '4', '0', '0', 'pedestrian'], ['1217', '146', '40', '21', '1', '4', '0', '0', 'pedestrian'], ['1134', '159', '9', '22', '1', '1', '0', '0', 'pedestrian'], ['1060', '138', '15', '19', '1', '1', '0', '0', 'pedestrian'], ['1038', '159', '11', '17', '1', '1', '0', '0', 'pedestrian'], ['387', '215', '144', '51', '0', '11', '0', '0', 'pedestrian'], ['331', '149', '94', '65', '1', '6', '0', '0', 'pedestrian'], ['179', '136', '107', '64', '1', '6', '0', '0', 'pedestrian'], ['79', '135', '98', '52', '1', '6', '0', '0', 'pedestrian'], ['32', '140', '92', '40', '1', '6', '0', '0', 'pedestrian'], ['0', '231', '91', '89', '1', '6', '1', '0', 'pedestrian'], ['0', '380', '55', '65', '1', '4', '1', '0', 'pedestrian'], ['315', '409', '42', '19', '1', '10', '0', '0', 'pedestrian'], ['685', '121', '31', '20', '1', '5', '0', '0', 'pedestrian'], ['1306', '153', '54', '43', '1', '6', '0', '0', 'pedestrian'], ['1036', '106', '20', '14', '1', '4', '0', '0', 'pedestrian'], ['866', '108', '12', '17', '0', '11', '0', '0', 'pedestrian'], ['867', '99', '6', '10', '1', '1', '0', '0', 'pedestrian'], ['853', '67', '14', '12', '1', '4', '0', '0', 'pedestrian'], ['840', '50', '12', '10', '1', '4', '0', '0', 'pedestrian'], ['857', '44', '9', '12', '1', '4', '0', '0', 'pedestrian'], ['846', '36', '12', '11', '1', '4', '0', '0', 'pedestrian'], ['840', '43', '9', '10', '1', '4', '0', '0', 'pedestrian'], ['820', '41', '11', '10', '1', '4', '0', '0', 'pedestrian'], ['830', '35', '8', '11', '1', '4', '0', '0', 'pedestrian'], ['826', '26', '10', '8', '1', '4', '0', '0', 'pedestrian'], ['802', '23', '9', '8', '1', '4', '0', '0', 'pedestrian'], ['769', '46', '24', '8', '1', '4', '0', '0', 'pedestrian'], ['831', '17', '8', '7', '1', '4', '0', '0', 'pedestrian'], ['680', '0', '80', '49', '0', '0', '0', '0', 'pedestrian'], ['763', '5', '6', '6', '1', '4', '0', '0', 'pedestrian'], ['771', '4', '7', '7', '1', '4', '0', '0', 'pedestrian'], ['769', '11', '7', '5', '1', '4', '0', '0', 'pedestrian'], ['790', '10', '7', '7', '1', '4', '0', '0', 'pedestrian'], ['780', '10', '8', '7', '1', '4', '0', '0', 'pedestrian'], ['781', '4', '5', '6', '1', '4', '0', '0', 'pedestrian'], ['884', '27', '12', '8', '1', '4', '0', '0', 'pedestrian'], ['792', '3', '6', '6', '1', '4', '0', '0', 'pedestrian'], ['805', '7', '6', '9', '1', '4', '0', '0', 'pedestrian'], ['798', '1', '5', '8', '1', '4', '0', '0', 'pedestrian'], ['820', '0', '55', '31', '0', '0', '0', '0', 'pedestrian']]\n",
            "Number of pedestrain labels:  57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "bbox = []\n",
        "new_bbox = np.array([])\n",
        "for i in range(len(new_list)):\n",
        "  bbox.append(np.array([new_list[i][0], new_list[i][1], new_list[i][2], new_list[i][3]]))\n",
        "  new_bbox = np.array(bbox)\n",
        "print(bbox)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjzED9yI5YvM",
        "outputId": "f83c6bbd-e43c-4fa7-cbfe-09855c1a20c2"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array(['685', '463', '110', '65'], dtype='<U3'), array(['578', '328', '36', '38'], dtype='<U3'), array(['617', '327', '38', '44'], dtype='<U3'), array(['659', '350', '90', '40'], dtype='<U3'), array(['761', '346', '40', '44'], dtype='<U3'), array(['805', '350', '38', '41'], dtype='<U3'), array(['849', '346', '45', '47'], dtype='<U3'), array(['895', '349', '43', '44'], dtype='<U3'), array(['886', '297', '40', '43'], dtype='<U3'), array(['810', '305', '70', '40'], dtype='<U3'), array(['805', '256', '46', '28'], dtype='<U3'), array(['783', '234', '70', '27'], dtype='<U3'), array(['435', '535', '134', '57'], dtype='<U3'), array(['913', '179', '33', '31'], dtype='<U3'), array(['995', '126', '39', '23'], dtype='<U3'), array(['922', '106', '20', '21'], dtype='<U3'), array(['862', '154', '10', '17'], dtype='<U3'), array(['1217', '146', '40', '21'], dtype='<U4'), array(['1134', '159', '9', '22'], dtype='<U4'), array(['1060', '138', '15', '19'], dtype='<U4'), array(['1038', '159', '11', '17'], dtype='<U4'), array(['387', '215', '144', '51'], dtype='<U3'), array(['331', '149', '94', '65'], dtype='<U3'), array(['179', '136', '107', '64'], dtype='<U3'), array(['79', '135', '98', '52'], dtype='<U3'), array(['32', '140', '92', '40'], dtype='<U3'), array(['0', '231', '91', '89'], dtype='<U3'), array(['0', '380', '55', '65'], dtype='<U3'), array(['315', '409', '42', '19'], dtype='<U3'), array(['685', '121', '31', '20'], dtype='<U3'), array(['1306', '153', '54', '43'], dtype='<U4'), array(['1036', '106', '20', '14'], dtype='<U4'), array(['866', '108', '12', '17'], dtype='<U3'), array(['867', '99', '6', '10'], dtype='<U3'), array(['853', '67', '14', '12'], dtype='<U3'), array(['840', '50', '12', '10'], dtype='<U3'), array(['857', '44', '9', '12'], dtype='<U3'), array(['846', '36', '12', '11'], dtype='<U3'), array(['840', '43', '9', '10'], dtype='<U3'), array(['820', '41', '11', '10'], dtype='<U3'), array(['830', '35', '8', '11'], dtype='<U3'), array(['826', '26', '10', '8'], dtype='<U3'), array(['802', '23', '9', '8'], dtype='<U3'), array(['769', '46', '24', '8'], dtype='<U3'), array(['831', '17', '8', '7'], dtype='<U3'), array(['680', '0', '80', '49'], dtype='<U3'), array(['763', '5', '6', '6'], dtype='<U3'), array(['771', '4', '7', '7'], dtype='<U3'), array(['769', '11', '7', '5'], dtype='<U3'), array(['790', '10', '7', '7'], dtype='<U3'), array(['780', '10', '8', '7'], dtype='<U3'), array(['781', '4', '5', '6'], dtype='<U3'), array(['884', '27', '12', '8'], dtype='<U3'), array(['792', '3', '6', '6'], dtype='<U3'), array(['805', '7', '6', '9'], dtype='<U3'), array(['798', '1', '5', '8'], dtype='<U3'), array(['820', '0', '55', '31'], dtype='<U3')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(new_bbox))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDzX0FlhG2hQ",
        "outputId": "987a26a1-8f8f-4fde-ac94-8febef44dceb"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# default_box is going to be used if you will not draw any box on image above\n",
        "default_box = {'x': 68, 'y': 247, 'width': 555, 'height': 678, 'label': ''}\n",
        "\n",
        "# box = widget.bboxes[0] if widget.bboxes else default_box\n",
        "# box = np.array([\n",
        "#     box['x'],\n",
        "#     box['y'],\n",
        "#     box['x'] + box['width'],\n",
        "#     box['y'] + box['height']\n",
        "# ])"
      ],
      "metadata": {
        "id": "bVD-U4ygHnVs"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "IMAGE_PATH = \"/content/0000006_00159_d_0000001.jpg\"\n",
        "mask_predictor = SamPredictor(sam)\n",
        "\n",
        "image_bgr = cv2.imread(IMAGE_PATH)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask_predictor.set_image(image_rgb)\n",
        "\n",
        "for i in bbox:\n",
        "  masks, scores, logits = mask_predictor.predict(\n",
        "    box=new_bbox,\n",
        "    multimask_output=True\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "6T5Zy9k75PGp",
        "outputId": "472ade9f-e071-4447-92b5-bc5902164ad1"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-68c60c3e4412>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   masks, scores, logits = mask_predictor.predict(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_bbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmultimask_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, point_coords, point_labels, box, mask_input, multimask_output, return_logits)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mmask_input_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_input_torch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         masks, iou_predictions, low_res_masks = self.predict_torch(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mcoords_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mlabels_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/predictor.py\u001b[0m in \u001b[0;36mpredict_torch\u001b[0;34m(self, point_coords, point_labels, boxes, mask_input, multimask_output, return_logits)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# Embed prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         sparse_embeddings, dense_embeddings = self.model.prompt_encoder(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mboxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/prompt_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, points, boxes, masks)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mbox_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0msparse_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msparse_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_embeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 57 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "box_annotator = sv.BoxAnnotator(color=sv.Color.red())\n",
        "mask_annotator = sv.MaskAnnotator(color=sv.Color.red())\n",
        "\n",
        "detections = sv.Detections(\n",
        "    xyxy=sv.mask_to_xyxy(masks=masks),\n",
        "    mask=masks\n",
        ")\n",
        "detections = detections[detections.area == np.max(detections.area)]\n",
        "\n",
        "source_image = box_annotator.annotate(scene=image_bgr.copy(), detections=detections, skip_label=True)\n",
        "segmented_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=[source_image, segmented_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['source image', 'segmented image']\n",
        ")"
      ],
      "metadata": {
        "id": "nOlDQcUZ5PDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as v\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=masks,\n",
        "    grid_size=(1, 4),\n",
        "    size=(16, 4)\n",
        ")"
      ],
      "metadata": {
        "id": "P_Nj3aSs5PBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gtdJ1tZb5O-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6lXtyv05O5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6Z6W3vO5O2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ORrDOe9l5HuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GdEWYIze5Hrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7pPwo3lA5Hov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJQlnBjq5Hji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Q-wjbkt5Hgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ONNzE7b5HeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated Mask Generation\n",
        "\n",
        "To run automatic mask generation, provide a SAM model to the `SamAutomaticMaskGenerator` class. Set the path below to the SAM checkpoint. Running on CUDA and with the default model is recommended."
      ],
      "metadata": {
        "id": "pi3C4uDWo10h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_generator = SamAutomaticMaskGenerator(sam)"
      ],
      "metadata": {
        "id": "CtymFaiKyQ57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Union, Optional\n",
        "from dataclasses_json import dataclass_json\n",
        "from supervision import Detections\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOCategory:\n",
        "    id: int\n",
        "    name: str\n",
        "    supercategory: str\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOImage:\n",
        "    id: int\n",
        "    width: int\n",
        "    height: int\n",
        "    file_name: str\n",
        "    license: int\n",
        "    date_captured: str\n",
        "    coco_url: Optional[str] = None\n",
        "    flickr_url: Optional[str] = None\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOAnnotation:\n",
        "    id: int\n",
        "    image_id: int\n",
        "    category_id: int\n",
        "    segmentation: List[List[float]]\n",
        "    area: float\n",
        "    bbox: Tuple[float, float, float, float]\n",
        "    iscrowd: int\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOLicense:\n",
        "    id: int\n",
        "    name: str\n",
        "    url: str\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOJson:\n",
        "    images: List[COCOImage]\n",
        "    annotations: List[COCOAnnotation]\n",
        "    categories: List[COCOCategory]\n",
        "    licenses: List[COCOLicense]\n",
        "\n",
        "\n",
        "def load_coco_json(json_file: str) -> COCOJson:\n",
        "    import json\n",
        "\n",
        "    with open(json_file, \"r\") as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    return COCOJson.from_dict(json_data)\n",
        "\n",
        "\n",
        "class COCOJsonUtility:\n",
        "    @staticmethod\n",
        "    def get_annotations_by_image_id(coco_data: COCOJson, image_id: int) -> List[COCOAnnotation]:\n",
        "        return [annotation for annotation in coco_data.annotations if annotation.image_id == image_id]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_annotations_by_image_path(coco_data: COCOJson, image_path: str) -> Optional[List[COCOAnnotation]]:\n",
        "        image = COCOJsonUtility.get_image_by_path(coco_data, image_path)\n",
        "        if image:\n",
        "            return COCOJsonUtility.get_annotations_by_image_id(coco_data, image.id)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def get_image_by_path(coco_data: COCOJson, image_path: str) -> Optional[COCOImage]:\n",
        "        for image in coco_data.images:\n",
        "            if image.file_name == image_path:\n",
        "                return image\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def annotations2detections(annotations: List[COCOAnnotation]) -> Detections:\n",
        "        class_id, xyxy = [], []\n",
        "\n",
        "        for annotation in annotations:\n",
        "            x_min, y_min, width, height = annotation.bbox\n",
        "            class_id.append(annotation.category_id)\n",
        "            xyxy.append([\n",
        "                x_min,\n",
        "                y_min,\n",
        "                x_min + width,\n",
        "                y_min + height\n",
        "            ])\n",
        "\n",
        "        return Detections(\n",
        "            xyxy=np.array(xyxy, dtype=int),\n",
        "            class_id=np.array(class_id, dtype=int)\n",
        "        )"
      ],
      "metadata": {
        "id": "dZSU9BpHr2gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Dataset from Roboflow"
      ],
      "metadata": {
        "id": "W-jQ5c4TQAic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "import roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "rf = Roboflow()\n",
        "\n",
        "project = rf.workspace(\"hashira-fhxpj\").project(\"mri-brain-tumor\")\n",
        "dataset = project.version(1).download(\"coco\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxH9V2nHQC4M",
        "outputId": "cc1146b8-4816-4b9e-edb8-5c366026b82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\rvisit https://app.roboflow.com/auth-cli to get your authentication token.\n",
            "Paste the authentication token here: ··········\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in MRI-BRAIN-TUMOR-1 to coco: 100% [1561113 / 1561113] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to MRI-BRAIN-TUMOR-1 in coco:: 100%|██████████| 85/85 [00:00<00:00, 2992.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_SET_SUBDIRECTORY = \"test\"\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\"\n",
        "IMAGES_DIRECTORY_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY)\n",
        "ANNOTATIONS_FILE_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY, ANNOTATIONS_FILE_NAME)"
      ],
      "metadata": {
        "id": "N-Xi4Dx0QuRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco_data = load_coco_json(json_file=ANNOTATIONS_FILE_PATH)\n",
        "\n",
        "CLASSES = [\n",
        "    category.name\n",
        "    for category\n",
        "    in coco_data.categories\n",
        "    if category.supercategory != 'none'\n",
        "]\n",
        "\n",
        "IMAGES = [\n",
        "    image.file_name\n",
        "    for image\n",
        "    in coco_data.images\n",
        "]"
      ],
      "metadata": {
        "id": "a8b3oKP0QyiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFQwR9-aQ0kx",
        "outputId": "eb84c5b1-4683-4d56-8e7c-00673de1cc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['YES-TUMOR']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Image Bounding Box to Mask"
      ],
      "metadata": {
        "id": "s3WqT5qTQ6tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed to allow easy reproduction of the experiment\n",
        "\n",
        "import random\n",
        "random.seed(10)"
      ],
      "metadata": {
        "id": "MuUKYCLnRAaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "5_78Qpvi9vUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL\n",
        "\n",
        "\n",
        "\n",
        "# EXAMPLE_IMAGE_NAME = random.choice(IMAGES)\n",
        "EXAMPLE_IMAGE_NAME = \"Y16_JPG.rf.96e3fc38718c5f64776810040e63363c.jpg\"\n",
        "EXAMPLE_IMAGE_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY, EXAMPLE_IMAGE_NAME)\n",
        "\n",
        "\n",
        "print(\"File name: \", EXAMPLE_IMAGE_NAME)\n",
        "# load dataset annotations\n",
        "annotations = COCOJsonUtility.get_annotations_by_image_path(coco_data=coco_data, image_path=EXAMPLE_IMAGE_NAME)\n",
        "ground_truth = COCOJsonUtility.annotations2detections(annotations=annotations)\n",
        "\n",
        "# small hack - coco numerate classes from 1, model from 0 + we drop first redundant class from coco json\n",
        "ground_truth.class_id = ground_truth.class_id - 1\n",
        "\n",
        "# load image\n",
        "image_bgr = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# initiate annotator\n",
        "box_annotator = sv.BoxAnnotator(color=sv.Color.red())\n",
        "mask_annotator = sv.MaskAnnotator(color=sv.Color.red())\n",
        "\n",
        "# annotate ground truth\n",
        "annotated_frame_ground_truth = box_annotator.annotate(scene=image_bgr.copy(), detections=ground_truth, skip_label=True)\n",
        "\n",
        "output = []\n",
        "img_shp = image_rgb.shape\n",
        "img = np.zeros(img_shp)\n",
        "# run SAM inference\n",
        "mask_predictor.set_image(image_rgb)\n",
        "\n",
        "for i in ground_truth.xyxy:\n",
        "  masks, scores, logits = mask_predictor.predict(\n",
        "      box=i,\n",
        "      multimask_output=True\n",
        "  )\n",
        "\n",
        "  detections = sv.Detections(\n",
        "      xyxy=sv.mask_to_xyxy(masks=masks),\n",
        "      mask=masks\n",
        "  )\n",
        "  # detections = detections[detections.area == np.max(detections.area)]\n",
        "  detections = detections[detections.area == np.max(detections.area)]\n",
        "  # output += detections.mask\n",
        "  print( \"masks__________________-------------\",detections.mask,)\n",
        "  print(type(detections))\n",
        "\n",
        "  # annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "  ################------Old code-----------################\n",
        "  # annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "  # sv.plot_images_grid(\n",
        "  #       images=[annotated_frame_ground_truth, annotated_image],\n",
        "  #       grid_size=(1, 2),\n",
        "  #       titles=['source image', 'segmented image']\n",
        "  # )\n",
        "  ##############----------end----------------###############\n",
        "\n",
        "  output.append(detections)\n",
        "  print(len(output))\n",
        "  print(output[0].mask)\n",
        "\n",
        "  for j in output:\n",
        "    annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=j[0:2])\n",
        "    print(annotated_image.shape, \"--------------------\")\n",
        "    img += annotated_image\n",
        "    img = img.reshape(416,416,1)\n",
        "\n",
        "    plt.imshow(img)\n",
        "\n",
        "\n",
        "    sv.plot_images_grid(\n",
        "          images=[annotated_frame_ground_truth, annotated_image],\n",
        "          grid_size=(1, 2),\n",
        "          titles=['source image', 'segmented image']\n",
        "    )\n",
        "    print(j[0].mask.shape)\n",
        "    imgplot = plt.imshow(j[0].mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "RHw4yH8XRCo9",
        "outputId": "fa995e10-b77e-478f-ebd6-87186f795aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File name:  Y16_JPG.rf.96e3fc38718c5f64776810040e63363c.jpg\n",
            "masks__________________------------- [[[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "<class 'supervision.detection.core.Detections'>\n",
            "1\n",
            "[[[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "(416, 416, 3) --------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-b620c78b40f5>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mannotated_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 519168 into shape (416,416,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mGWIXYer820E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}