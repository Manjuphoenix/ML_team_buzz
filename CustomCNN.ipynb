{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CustomCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-sMwli-ucDV"
      },
      "outputs": [],
      "source": [
        "#Drive upload\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Uploading all the disease images\n",
        "#1,73,851 -> Total Data points\n",
        "!unzip gdrive/MyDrive/PDPArchive.zip -d /content/gdrive/MyDrive/Content_Unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms\n",
        "from torch import utils\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "Lwc8DLVc6t7J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on\", device)\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "LM7RA6SZ-qdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an Even DataSet to Work with\n",
        "\n",
        "path = '/gdrive/MyDrive/Content_Unzip'\n",
        "cls = os.listdir(path)\n",
        "class_map = {}\n",
        "for cl in cls:\n",
        "  n = len(os.listdir(path + '/' + cl))\n",
        "  class_map.update(cl = n)\n",
        "print(class_map)\n",
        "\n",
        "\n",
        "#Transform to Tensor\n",
        "transform =  transforms.Compose(\n",
        "    [transforms.Resize(224),\n",
        "     transforms.ToTensor()])\n",
        "#Doubt : Why Exactly do they usually resize the Input to 224x224?\n",
        "#Note : Look up the concept of normalization again to fully understand why this is done\n",
        "data_ = datasets.ImageFolder(path, transform=transform)\n",
        "\n",
        "#Split into 3 subsets -> 40 | 30 | 30\n",
        "size1 = int(len(data_) * 0.4)\n",
        "size2 = (len(data_) - size1) / 2\n",
        "size3 = len(data_) - (size1 + size2)\n",
        "data1, data2, data3 = utils.data.random_split(data_, [size1, size2, size3])"
      ],
      "metadata": {
        "id": "W3zb92sEftrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_split__data(data):\n",
        "\n",
        "  testSize = int(len(data) * 0.3)\n",
        "  trainSize = len(data) - testSize\n",
        "  train_set, test_set = utils.data.random_split(data, [trainSize, testSize])\n",
        "\n",
        "  #Use Dataloader to load the data into an itterable form (Set 1)\n",
        "  train = utils.data.DataLoader(train_set, batch_size = 32, shuffle = True)\n",
        "  test = utils.data.DataLoader(test_set, batch_size = 32, shuffle = True)\n",
        "  \n",
        "  return train, test"
      ],
      "metadata": {
        "id": "29GeoD5D_jSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing DataDistribution between the two classes\n",
        "def compareDataSegments(data1loader, data2loader):\n",
        "  class_count_data1 = DataCount(data1loader)\n",
        "  class_count_data2 = DataCount(data2loader)\n",
        "\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_axes([0,0,1,1])\n",
        "  ax.set_title('Data Distribution between two batches of the Dataset', loc='left')\n",
        "\n",
        "  # Set position of bar on X axis\n",
        "  br1 = np.arange(len(class_count_data1))\n",
        "  br2 = [x + 0.25 for x in br1]\n",
        "\n",
        "  ax.bar(br1, class_count_data1, color = 'blue', width = 0.25, edgecolor ='black', label = 'Batch 1')\n",
        "  ax.bar(br2, class_count_data2, color = 'grey', width = 0.25, edgecolor ='black', label = 'Batch 2')\n",
        "\n",
        "  plt.xlabel('DataSets', fontweight='bold')\n",
        "  plt.ylabel('Class Count', fontweight='bold')\n",
        "  plt.xticks([r + 0.25 for r in range(len(class_count_data1))], [str(c) for c in range(len(class_count_data1))])\n",
        "    \n",
        "  plt.show()\n",
        "\n",
        "  #Class Names of Numeric Labels\n",
        "  classNames = os.listdir(path)\n",
        "  classNames.sort()\n",
        "  class_to_idx = {classNames[i]: i for i in range(len(classNames))}\n",
        "  print(class_to_idx)"
      ],
      "metadata": {
        "id": "mtHW9MTWGo3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the class distribution over a dataset\n",
        "def DataCount(dataloader):\n",
        "  class_count = [0, 0, 0, 0]\n",
        "  for i, batch in enumerate(dataloader):\n",
        "      image, classes = batch\n",
        "      labels = np.array(classes)\n",
        "      for label in labels:\n",
        "        for i in range(4):\n",
        "          if(label == i):\n",
        "            class_count[i] = class_count[i] + 1\n",
        "  return class_count"
      ],
      "metadata": {
        "id": "r5Ijj0pgS0bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the claculated class distributions\n",
        "def plot_class_distributions(class_count_train, class_count_test):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_axes([0,0,1,1])\n",
        "  ax.set_title('Data Distribution', loc='left')\n",
        "\n",
        "  # Set position of bar on X axis\n",
        "  br1 = np.arange(len(class_count_train))\n",
        "  br2 = [x + 0.25 for x in br1]\n",
        "  br3 = [x + 0.25 for x in br2]\n",
        "\n",
        "  ax.bar(br1, class_count_train, color = 'grey', width = 0.25, edgecolor ='black', label = 'Train')\n",
        "  ax.bar(br2, class_count_test, color = 'pink', width = 0.25, edgecolor ='black', label = 'Test')\n",
        "\n",
        "  plt.xlabel('DataSets', fontweight='bold')\n",
        "  plt.ylabel('Class Count', fontweight='bold')\n",
        "  plt.xticks([r + 0.25 for r in range(len(class_count_train))], [str(c) for c in range(len(class_count_train))])\n",
        "   \n",
        "  plt.show()\n",
        "\n",
        "  #Class Names of Numeric Labels\n",
        "  classNames = os.listdir(path)\n",
        "  classNames.sort()\n",
        "  class_to_idx = {classNames[i]: i for i in range(len(classNames))}\n",
        "  print(class_to_idx)"
      ],
      "metadata": {
        "id": "Toju7AgyQ3zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Class Ratios : Are they as even as expected?\n",
        "def check_class_ratio(class_count_train, class_count_val, class_count_test, classes):\n",
        "  class_ratios = []\n",
        "  #Initialize an empty zeroes array for all 39 classes\n",
        "\n",
        "  for i in range():\n",
        "    aggregate = class_count_train[i] + class_count_test[i] + class_count_val[i]\n",
        "    #print(aggregate)\n",
        "    class_ratios[i][0] = round((class_count_train[i] / aggregate) * 100, 2)\n",
        "    class_ratios[i][2] = round((class_count_test[i] / aggregate) * 100, 2)\n",
        "\n",
        "  print(\"Rough Percentage of Class Division amongst the three train, test and validate sets\")\n",
        "  for i in range():\n",
        "    print(class_ratios[i])\n",
        "    print()"
      ],
      "metadata": {
        "id": "i0Wgfb51SmEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a simple CNN architechture\n",
        "class SimpleCustomCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCustomCNN, self).__init__()\n",
        "\n",
        "    #Defining a sequential model layers\n",
        "    self.c1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=5, padding=0, stride=1),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.c2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=3, padding=0, stride=1),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc1 = nn.Linear(in_features = 54*54*32, out_features = 39)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.c1(x)\n",
        "    output = self.c2(output)\n",
        "    output = output.reshape(output.size(0), -1)\n",
        "    #or nn.Flatten()\n",
        "    output = self.fc1(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "D6dlapUIrcEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling all the functions to visualize the Data\n",
        "def datasets_visualization(train, test):\n",
        "\n",
        "  dataiter = iter(train)\n",
        "  images, classes = dataiter.next()\n",
        "\n",
        "  print(type(images))\n",
        "  print(images.shape)\n",
        "  print(classes.shape)\n",
        "\n",
        "  class_count_train = DataCount(train)\n",
        "  class_count_test = DataCount(test)\n",
        "\n",
        "  #Check if the Ratio of the Train:Val:Test has been maintained through the classes:\n",
        "  check_class_ratio(class_count_train, class_count_test, classes)\n",
        "\n",
        "  #Plot to Visualize the way Data is Distributed between the sets\n",
        "  plot_class_distributions(class_count_train, class_count_test)\n"
      ],
      "metadata": {
        "id": "3ZNgODvVKVJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train__model(e, train, model, optimizer):\n",
        "\n",
        "  train_losses = []\n",
        "  train_accuracy = []\n",
        "\n",
        "  for epoch in range(e):\n",
        "    model.train()\n",
        "\n",
        "    run_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for img, class_ in train:\n",
        "          img, class_ = img.to(device), class_.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(img)\n",
        "          loss = lossCriteria(output, class_)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          run_loss += loss.item() \n",
        "\n",
        "          _, prediction = output.max(1)\n",
        "          total += class_.size(0)\n",
        "          correct += prediction.eq(class_).sum().item()\n",
        "    \n",
        "    train_loss = run_loss/len(train.sampler)\n",
        "    accuracy = 100.*correct/total\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracy.append(accuracy)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f}'.format(epoch, train_loss, accuracy))\n",
        "\n",
        "  return train_losses, train_accuracy\n"
      ],
      "metadata": {
        "id": "Nc-wwEHoKDhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(e, test, model):\n",
        "\n",
        "  final_losses = []\n",
        "  final_accuracy = []\n",
        "\n",
        "  for epoch in range(e):\n",
        "    model.eval()\n",
        "\n",
        "    run_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for img, class_ in test:\n",
        "        img, class_ = img.to(device), class_.to(device)\n",
        "        output = model(img)\n",
        "        loss = lossCriteria(output, class_)\n",
        "        run_loss += loss.item()\n",
        "\n",
        "        _, prediction = output.max(1)\n",
        "        total += class_.size(0)\n",
        "        correct += prediction.eq(class_).sum().item()\n",
        "      \n",
        "\n",
        "      test_loss = run_loss/len(test.sampler)\n",
        "      accuracy = 100.*correct/total\n",
        "\n",
        "      final_losses.append(test_loss)\n",
        "      final_accuracy.append(accuracy)\n",
        "      print('Epoch: {} \\tTest Loss: {:.4f} \\tTest Accuracy: {:.4f}'.format(epoch, test_loss, accuracy))\n",
        "  \n",
        "  return final_losses, final_accuracy\n",
        "  "
      ],
      "metadata": {
        "id": "vA3ofUWOSFJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visulaize the Results\n",
        "def plot_acc_curve(train_accuracy, test_accuracy):\n",
        "  plt.plot(train_accuracy, color='green')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Training Accuracy')\n",
        " \n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_curve(train_losses, test_losses):\n",
        "  plt.plot(train_losses, color='green')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title('Training Loss')\n",
        " \n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zYEjOojiNhLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Call the Train and Validate and Test Functions\n",
        "def train_test_models(model_, train, test):\n",
        "  train_losses, train_accuracy = train__model(50, train, model_)\n",
        "  test_losses, test_accuracy = test_model(1, test, model_)\n",
        "\n",
        "  plot_loss_curve(train_losses, test_losses)\n",
        "  plot_acc_curve(train_accuracy, test_accuracy)\n"
      ],
      "metadata": {
        "id": "g6dJE7m-NmVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting into training and testing datasets\n",
        "train1, test1 = process_and_split__data(data1)\n",
        "train2, test2 = process_and_split__data(data2)\n",
        "train3, test3 = process_and_split__data(data3)\n",
        "\n",
        "#Visualizing the Induvidual Datasets :\n",
        "print(\"Dataset Segment 1 : \")\n",
        "datasets_visualization(train1, test1)\n",
        "print(\"Dataset Segment 2 : \")\n",
        "datasets_visualization(train2, test2)\n",
        "print(\"Dataset Segment 3 : \")\n",
        "datasets_visualization(train3, test3)\n",
        "\n",
        "#Compare these Data Segemnts\n",
        "print(\"Dataset Segment 1 v.s 2: \")\n",
        "compareDataSegments(data1, data2)\n",
        "print(\"Dataset Segment 2 v.s 3: \")\n",
        "compareDataSegments(data2, data3)\n",
        "print(\"Dataset Segment 1 v.s 3: \")\n",
        "compareDataSegments(data1, data3)"
      ],
      "metadata": {
        "id": "BRFxbAfzW0LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataSets are clearly un-even. They require some segmentation techniques to even out the class distributions"
      ],
      "metadata": {
        "id": "yNohgukiaY4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the output from all three random data partitions give us a more or less similar accuracy and loss curve, we can take the average of these three as the final accuracy. If Further investigation is required, we may go ahead and re-run this whole runtime so that the next random three data segments can be tested. Those results can further strengthen the conclusion"
      ],
      "metadata": {
        "id": "1Uh911ilZ2rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross Entropy Function\n",
        "lossCriteria = nn.CrossEntropyLoss()\n",
        "\n",
        "#Initialize model and optimizer 1\n",
        "model1 = SimpleCustomCNN().to(device)\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "print(model1)\n",
        "#Calling the training function for model 1\n",
        "train_test_models(model1, train1, test1, optimizer1)\n",
        "\n",
        "\n",
        "#Initialize model and optimizer 2\n",
        "model1 = SimpleCustomCNN().to(device)\n",
        "optimizer2 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "print(model1)\n",
        "#Calling the training function for model 2\n",
        "train_test_models(model1, train1, test1, optimizer2)\n",
        "\n",
        "\n",
        "#Initialize model and optimizer 3\n",
        "model1 = SimpleCustomCNN().to(device)\n",
        "optimizer3 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "print(model1)\n",
        "#Calling the training function for model 3\n",
        "train_test_models(model1, train1, test1, optimizer3)"
      ],
      "metadata": {
        "id": "Z1IEBcDXZTjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#Visualize through a confusion matrix\n",
        "\n",
        "#Getting the list of prediction made by model\n",
        "def get_all_preds(model, loader):\n",
        "    all_preds = torch.tensor([])\n",
        "    for batch in loader:\n",
        "        images, labels = batch\n",
        "\n",
        "        preds = model(images)\n",
        "        all_preds = torch.cat(\n",
        "            (all_preds, preds)\n",
        "            ,dim=0\n",
        "        )\n",
        "    return all_preds\n",
        "\n",
        "#Counting the total number of correct predictions made\n",
        "def get_num_correct():\n",
        "\n",
        "#Calling above two functions\n",
        "with torch.no_grad():\n",
        "    prediction_loader = torch.utils.data.DataLoader(train1, batch_size=10000)\n",
        "    train1_preds = get_all_preds(network, prediction_loader)\n",
        "preds_correct = get_num_correct(train1_preds, train1.targets)\n",
        "\n",
        "print('Total Correct:', preds_correct)\n",
        "print('Accuracy:', preds_correct / len(train1))'''"
      ],
      "metadata": {
        "id": "iGYnbqm0fv3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving model state:\n",
        "#torch.save(model.state_dict(), '/content/gdrive/MyDrive/CustomCNN_93.4911_apple')"
      ],
      "metadata": {
        "id": "LD0gwuXsKhQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Previously saved model\n",
        "'''\n",
        "modelOld =  SimpleCustomCNN().to(device)\n",
        "modelOld.load_state_dict = torch.load('/content/gdrive/MyDrive/CustomCNN_93.4911_apple')\n",
        "print(modelOld)\n",
        "modelOld.to(device)\n",
        "'''"
      ],
      "metadata": {
        "id": "C0cTdODyLCWa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}